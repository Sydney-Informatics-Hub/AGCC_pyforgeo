{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science for Geoscience\n",
    "\n",
    "Let's use some standard Machine Learning tools availble in Python packages to analyse some data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "Now we use our datasets to determine what tectonomagmatic parameters are related to ore formation. We use Support Vector Machines and Random Forrest classification methods. This notebook shows the two methods of data analysis, either looking at the general area of ore formation, or considering each ore formation point individually.\n",
    "\n",
    "\n",
    "## Area of formation (Partioned Data)\n",
    "\n",
    "#### Split the data into testing and training sets.\n",
    "With the \"training\" set we learn which parameters are important, and we test the validity of this with the \"testing\" set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "#Import the tools for machine learning\n",
    "from sklearn import cross_validation\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Import data processing tools\n",
    "#import pickle\n",
    "#import matplotlib.mlab as ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbb=pandas.read_csv(\"../examples/ml_data_panda.csv\",index_col=0)\n",
    "aaa=bbb.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data array:  (221, 7)\n",
      "Positive (deposits) examples:  (45, 21)\n",
      "Negative (non-deposits) examples:  (176, 21)\n"
     ]
    }
   ],
   "source": [
    "#Put the data into the correct format\n",
    "\n",
    "#Get the parameters we want to include in the ML, indicies are from the List of Variables\n",
    "params=[6,9,14,17] \n",
    "# params=[6,9,10,11,12,13,14,15,16,17]\n",
    "\n",
    "#Recombine the features and the classification vectors. #Save the temporal-spatial parameters too for plotting purposes.\n",
    "andesData = np.c_[preprocessing.scale(aaa[:,params]),aaa[:,5],aaa[:,18],aaa[:,20]]\n",
    "\n",
    "#Do a 80/20 split of the data  to be used to make an example fit of the data\n",
    "andesTrain, andesTest,  = cross_validation.train_test_split(\\\n",
    "       andesData, test_size=0.2, random_state=1)\n",
    "\n",
    "print(\"Shape of data array: \", andesData.shape)\n",
    "\n",
    "#Number of 'positive' and 'negative' examples\n",
    "print(\"Positive (deposits) examples: \",np.shape(aaa[aaa[:,20]==1,:]))\n",
    "print(\"Negative (non-deposits) examples: \",np.shape(aaa[aaa[:,20]==0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]Prediction-testing set (expected result):\n",
      "[ 1.  1.  1.  0.  1.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  0.\n",
      "  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      "Prediction of test (actual result):\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "Single result:\n",
      "0.711111111111\n",
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Cross fold validation results:\n",
      "[ 0.82222222  0.84090909  0.86363636  0.77272727  0.79545455]\n"
     ]
    }
   ],
   "source": [
    "#Make the classifier\n",
    "clf = SVC(probability=True,verbose=True,cache_size=1000,class_weight=None)\n",
    "\n",
    "\n",
    "#Now make a single classification for plotting and typicla results\n",
    "#Train the classifier by fitting the parameters (features) to known results (targets/classes)\n",
    "clf.fit(andesTrain[:,0:-3], andesTrain[:,-1])\n",
    "\n",
    "print(\"Prediction-testing set (expected result):\")\n",
    "print(andesTest[:,-1])\n",
    "\n",
    "print(\"Prediction of test (actual result):\")\n",
    "print(clf.predict(andesTest[:,0:-3]))\n",
    "\n",
    "#Save the values of prediction\n",
    "p=numpy.array(clf.predict_proba(andesTest[:,0:-3]))\n",
    "\n",
    "#Get a single score out for the data\n",
    "svmParams=clf.score(andesTest[:,0:-3], andesTest[:,-1])\n",
    "print(\"Single result:\")\n",
    "print(svmParams)\n",
    "\n",
    "# print clf.support_vectors_\n",
    "\n",
    "###\n",
    "#Now get a cross-fold validation score using all subsets of the data\n",
    "scores = cross_validation.cross_val_score(clf, andesData[:,0:-3], andesData[:,-1], cv=5)\n",
    "\n",
    "print(\"Cross fold validation results:\")\n",
    "print(scores)\n",
    "\n",
    "#print clf.n_support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
